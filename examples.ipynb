{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\neptune\\common\\warnings.py:62: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from Modules.train import DataModule, Model, get_trainer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'architect_settings': {'name': 'model-test', 'backbone': {'name': 'maskrcnn-m', 'is_full': False, 'is_pretrained': True, 'is_freeze': False}, 'n_cls': 2}, 'dataset_settings': {'name': 'PennFudan', 'path': 'data/PennFudanPed', 'img_size': 320}, 'training_settings': {'gpu_ids': [0], 'n_gpu': 1, 'loss': 'none', 'ckpt_path': './mode/test', 'n_epoch': 50, 'n_batch': 2, 'num_workers': 12, 'optimizer': 'adam', 'lr_scheduler': 'step', 'early_stopping': False, 'lr': 0.0001, 'lr_step': 10, 'lr_decay': 0.8, 'momentum': 0.9, 'weight_decay': 0.005}}\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "task = \"detection\"\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "        project=\"kaori/AISeed\",\n",
    "        # api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyZjZiMDA2YS02MDM3LTQxZjQtOTE4YS1jODZkMTJjNGJlMDYifQ==\",\n",
    "        log_model_checkpoints=False,\n",
    "        tags=[task]\n",
    "    )\n",
    "\n",
    "with open(\"Modules/config.yaml\", 'r') as stream:\n",
    "    PARAMS = yaml.safe_load(stream)\n",
    "    PARAMS = PARAMS['detect']\n",
    "    print(PARAMS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLUSERSPROFILE\n",
      "APPDATA\n",
      "APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL\n",
      "CHROME_CRASHPAD_PIPE_NAME\n",
      "COMMONPROGRAMFILES\n",
      "COMMONPROGRAMFILES(X86)\n",
      "COMMONPROGRAMW6432\n",
      "COMPUTERNAME\n",
      "COMSPEC\n",
      "CONDA_DEFAULT_ENV\n",
      "CONDA_EXE\n",
      "CONDA_EXES\n",
      "CONDA_PREFIX\n",
      "CONDA_PROMPT_MODIFIER\n",
      "CONDA_PYTHON_EXE\n",
      "CONDA_ROOT\n",
      "CONDA_SHLVL\n",
      "DRIVERDATA\n",
      "EFC_19008\n",
      "ELECTRON_RUN_AS_NODE\n",
      "HOMEDRIVE\n",
      "HOMEPATH\n",
      "JAVA_HOME\n",
      "JPY_INTERRUPT_EVENT\n",
      "LOCALAPPDATA\n",
      "LOGONSERVER\n",
      "NUMBER_OF_PROCESSORS\n",
      "ONEDRIVE\n",
      "ONEDRIVECOMMERCIAL\n",
      "ORIGINAL_XDG_CURRENT_DESKTOP\n",
      "OS\n",
      "PATH\n",
      "PATHEXT\n",
      "PROCESSOR_ARCHITECTURE\n",
      "PROCESSOR_IDENTIFIER\n",
      "PROCESSOR_LEVEL\n",
      "PROCESSOR_REVISION\n",
      "PROGRAMDATA\n",
      "PROGRAMFILES\n",
      "PROGRAMFILES(X86)\n",
      "PROGRAMW6432\n",
      "PROMPT\n",
      "PSMODULEPATH\n",
      "PUBLIC\n",
      "PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING\n",
      "PYTHONIOENCODING\n",
      "PYTHONUNBUFFERED\n",
      "PYTHONUTF8\n",
      "SESSIONNAME\n",
      "SYSTEMDRIVE\n",
      "SYSTEMROOT\n",
      "TEMP\n",
      "TMP\n",
      "USERDNSDOMAIN\n",
      "USERDOMAIN\n",
      "USERDOMAIN_ROAMINGPROFILE\n",
      "USERNAME\n",
      "USERPROFILE\n",
      "VSCODE_AMD_ENTRYPOINT\n",
      "VSCODE_CODE_CACHE_PATH\n",
      "VSCODE_CRASH_REPORTER_PROCESS_TYPE\n",
      "VSCODE_CWD\n",
      "VSCODE_HANDLES_UNCAUGHT_ERRORS\n",
      "VSCODE_IPC_HOOK\n",
      "VSCODE_L10N_BUNDLE_LOCATION\n",
      "VSCODE_NLS_CONFIG\n",
      "VSCODE_PID\n",
      "WINDIR\n",
      "_CONDA_OLD_CHCP\n",
      "PYDEVD_USE_FRAME_EVAL\n",
      "TERM\n",
      "CLICOLOR\n",
      "PAGER\n",
      "GIT_PAGER\n",
      "MPLBACKEND\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for key in os.environ:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "img_size = PARAMS['dataset_settings']['img_size']\n",
    "transforms_img = A.Compose([\n",
    "    A.RandomResizedCrop(img_size, img_size),  # Random crop and resize\n",
    "    A.HorizontalFlip(),  # Random horizontal flip\n",
    "    A.VerticalFlip(),  # Random vertical flip\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),  # Convert to tensor\n",
    "])\n",
    "\n",
    "data = DataModule(PARAMS['dataset_settings'], PARAMS['training_settings'], [None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\neptune\\common\\warnings.py:62: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NeptuneMissingApiTokenException",
     "evalue": "\n\n----NeptuneMissingApiTokenException-------------------------------------------\n\nThe Neptune client couldn't find your API token.\n\nYou can get it here:\n    - https://app.neptune.ai/get_my_api_token\n\nThere are two options to add it:\n    - specify it in your code\n    - set an environment variable in your operating system.\n\nCODE\nPass the token to the init_run() function via the api_token argument:\n    neptune.init_run(project='WORKSPACE_NAME/PROJECT_NAME', api_token='YOUR_API_TOKEN')\n\nENVIRONMENT VARIABLE (Recommended option)\nor export or set an environment variable depending on your operating system:\n\n    Linux/Unix\n    In your terminal run:\n        export NEPTUNE_API_TOKEN=\"YOUR_API_TOKEN\"\n\n    Windows\n    In your CMD run:\n        set NEPTUNE_API_TOKEN=\"YOUR_API_TOKEN\"\n\nand skip the api_token argument of the init_run() function:\n    neptune.init_run(project='WORKSPACE_NAME/PROJECT_NAME')\n\nYou may also want to check the following docs pages:\n    - https://docs.neptune.ai/setup/setting_api_token/\n\nNeed help?-> https://docs.neptune.ai/getting_help\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNeptuneMissingApiTokenException\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# %%script false --no-raise-error\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m neptune_logger\u001b[39m.\u001b[39;49mlog_hyperparams(params\u001b[39m=\u001b[39;49mPARAMS)\n\u001b[0;32m      3\u001b[0m model \u001b[39m=\u001b[39m Model(PARAMS\u001b[39m=\u001b[39mPARAMS, task \u001b[39m=\u001b[39m task)\n\u001b[0;32m      4\u001b[0m trainer \u001b[39m=\u001b[39m get_trainer(PARAMS[\u001b[39m'\u001b[39m\u001b[39mtraining_settings\u001b[39m\u001b[39m'\u001b[39m], neptune_logger)\n",
      "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\lightning_utilities\\core\\rank_zero.py:27\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     28\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\pytorch_lightning\\loggers\\neptune.py:406\u001b[0m, in \u001b[0;36mNeptuneLogger.log_hyperparams\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    403\u001b[0m parameters_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPARAMETERS_KEY\n\u001b[0;32m    404\u001b[0m parameters_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_path_with_prefix(parameters_key)\n\u001b[1;32m--> 406\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun[parameters_key] \u001b[39m=\u001b[39m params\n",
      "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\lightning_fabric\\loggers\\logger.py:114\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m rank_zero_only\u001b[39m.\u001b[39mrank \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m _DummyExperiment()\n\u001b[1;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\pytorch_lightning\\loggers\\neptune.py:358\u001b[0m, in \u001b[0;36mNeptuneLogger.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    355\u001b[0m \u001b[39m@rank_zero_experiment\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Run:\n\u001b[0;32m    357\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_instance:\n\u001b[1;32m--> 358\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_instance \u001b[39m=\u001b[39m neptune\u001b[39m.\u001b[39minit_run(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_neptune_init_args)\n\u001b[0;32m    359\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve_run_data()\n\u001b[0;32m    360\u001b[0m         \u001b[39m# make sure that we've log integration version for newly created\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\neptune\\metadata_containers\\run.py:364\u001b[0m, in \u001b[0;36mRun.__init__\u001b[1;34m(self, with_id, project, api_token, custom_run_id, mode, name, description, tags, source_files, capture_stdout, capture_stderr, capture_hardware_metrics, fail_on_exception, monitoring_namespace, flush_period, proxies, capture_traceback, git_ref, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m Mode\u001b[39m.\u001b[39mOFFLINE \u001b[39mor\u001b[39;00m mode \u001b[39m==\u001b[39m Mode\u001b[39m.\u001b[39mDEBUG:\n\u001b[0;32m    362\u001b[0m     project \u001b[39m=\u001b[39m OFFLINE_PROJECT_QUALIFIED_NAME\n\u001b[1;32m--> 364\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(project\u001b[39m=\u001b[39;49mproject, api_token\u001b[39m=\u001b[39;49mapi_token, mode\u001b[39m=\u001b[39;49mmode, flush_period\u001b[39m=\u001b[39;49mflush_period, proxies\u001b[39m=\u001b[39;49mproxies)\n",
      "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\neptune\\metadata_containers\\metadata_container.py:113\u001b[0m, in \u001b[0;36mMetadataContainer.__init__\u001b[1;34m(self, project, api_token, mode, flush_period, proxies)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock: threading\u001b[39m.\u001b[39mRLock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mRLock()\n\u001b[0;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state: ContainerState \u001b[39m=\u001b[39m ContainerState\u001b[39m.\u001b[39mCREATED\n\u001b[1;32m--> 113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend: NeptuneBackend \u001b[39m=\u001b[39m get_backend(mode\u001b[39m=\u001b[39;49mmode, api_token\u001b[39m=\u001b[39;49mapi_token, proxies\u001b[39m=\u001b[39;49mproxies)\n\u001b[0;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_project_qualified_name: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m conform_optional(project, QualifiedName)\n\u001b[0;32m    116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_project_api_object: Project \u001b[39m=\u001b[39m project_name_lookup(\n\u001b[0;32m    117\u001b[0m     backend\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_project_qualified_name\n\u001b[0;32m    118\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\neptune\\internal\\backends\\factory.py:31\u001b[0m, in \u001b[0;36mget_backend\u001b[1;34m(mode, api_token, proxies)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_backend\u001b[39m(mode: Mode, api_token: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, proxies: Optional[\u001b[39mdict\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NeptuneBackend:\n\u001b[0;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m Mode\u001b[39m.\u001b[39mASYNC:\n\u001b[1;32m---> 31\u001b[0m         \u001b[39mreturn\u001b[39;00m HostedNeptuneBackend(credentials\u001b[39m=\u001b[39mCredentials\u001b[39m.\u001b[39;49mfrom_token(api_token\u001b[39m=\u001b[39;49mapi_token), proxies\u001b[39m=\u001b[39mproxies)\n\u001b[0;32m     32\u001b[0m     \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m Mode\u001b[39m.\u001b[39mSYNC:\n\u001b[0;32m     33\u001b[0m         \u001b[39mreturn\u001b[39;00m HostedNeptuneBackend(credentials\u001b[39m=\u001b[39mCredentials\u001b[39m.\u001b[39mfrom_token(api_token\u001b[39m=\u001b[39mapi_token), proxies\u001b[39m=\u001b[39mproxies)\n",
      "File \u001b[1;32mc:\\Users\\197796\\Anaconda3\\envs\\AISeed\\lib\\site-packages\\neptune\\internal\\credentials.py:49\u001b[0m, in \u001b[0;36mCredentials.from_token\u001b[1;34m(cls, api_token)\u001b[0m\n\u001b[0;32m     46\u001b[0m     api_token \u001b[39m=\u001b[39m ANONYMOUS_API_TOKEN_CONTENT\n\u001b[0;32m     48\u001b[0m \u001b[39mif\u001b[39;00m api_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mraise\u001b[39;00m NeptuneMissingApiTokenException()\n\u001b[0;32m     51\u001b[0m api_token \u001b[39m=\u001b[39m api_token\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     52\u001b[0m token_dict \u001b[39m=\u001b[39m Credentials\u001b[39m.\u001b[39m_api_token_to_dict(api_token)\n",
      "\u001b[1;31mNeptuneMissingApiTokenException\u001b[0m: \n\n----NeptuneMissingApiTokenException-------------------------------------------\n\nThe Neptune client couldn't find your API token.\n\nYou can get it here:\n    - https://app.neptune.ai/get_my_api_token\n\nThere are two options to add it:\n    - specify it in your code\n    - set an environment variable in your operating system.\n\nCODE\nPass the token to the init_run() function via the api_token argument:\n    neptune.init_run(project='WORKSPACE_NAME/PROJECT_NAME', api_token='YOUR_API_TOKEN')\n\nENVIRONMENT VARIABLE (Recommended option)\nor export or set an environment variable depending on your operating system:\n\n    Linux/Unix\n    In your terminal run:\n        export NEPTUNE_API_TOKEN=\"YOUR_API_TOKEN\"\n\n    Windows\n    In your CMD run:\n        set NEPTUNE_API_TOKEN=\"YOUR_API_TOKEN\"\n\nand skip the api_token argument of the init_run() function:\n    neptune.init_run(project='WORKSPACE_NAME/PROJECT_NAME')\n\nYou may also want to check the following docs pages:\n    - https://docs.neptune.ai/setup/setting_api_token/\n\nNeed help?-> https://docs.neptune.ai/getting_help\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "neptune_logger.log_hyperparams(params=PARAMS)\n",
    "model = Model(PARAMS=PARAMS, task = task)\n",
    "trainer = get_trainer(PARAMS['training_settings'], neptune_logger)\n",
    "# \n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.get(\"NEPTUNE_API_TOKEN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "import torch\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "import os\n",
    "from torchvision import transforms\n",
    "\n",
    "with open(\"models/class_name.txt\", \"r\", encoding='utf-8') as f:\n",
    "    class_names = f.read().splitlines()\n",
    "\n",
    "model_list = [name.split('.')[0] for name in os.listdir(\"models\") if name.endswith('ckpt')]\n",
    "model_list += [\"fcn\", \"resnet\", \"fasterrcnn\", \"maskrcnn\"]\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "    std=[1/0.229, 1/0.224, 1/0.255]\n",
    ")\n",
    "\n",
    "def predict(image, model_choice):\n",
    "    labels, detection = None, None\n",
    "    with open(\"Modules/config.yaml\", 'r') as stream:\n",
    "            PARAMS = yaml.safe_load(stream)\n",
    "            PARAMS = PARAMS['segment']\n",
    "    PARAMS['architect_settings']['backbone']['is_full'] = True\n",
    "    if(model_choice == \"fcn\"):\n",
    "        PARAMS['architect_settings']['backbone']['name'] = 'fcn-m'    \n",
    "        model = Model(PARAMS, task=\"segmentation\")\n",
    "    elif(model_choice == \"resnet\"):\n",
    "        PARAMS['architect_settings']['backbone']['name'] = 'resnet-s'    \n",
    "        model = Model(PARAMS, task=\"classification\")\n",
    "    elif(model_choice == \"fasterrcnn\"):\n",
    "        PARAMS['architect_settings']['backbone']['name'] = 'fasterrcnn-s'    \n",
    "        model = Model(PARAMS, task=\"detection\")\n",
    "    elif(model_choice == \"maskrcnn\"):\n",
    "        PARAMS['architect_settings']['backbone']['name'] = 'maskrcnn-s'    \n",
    "        model = Model(PARAMS, task=\"detection\")\n",
    "    else:\n",
    "        model = Model.load_from_checkpoint(f\"models/{model_choice}.ckpt\").cpu()\n",
    "    model.eval()\n",
    "    transforms = model.model.preprocess\n",
    "    tensor_image = transforms(image)\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(tensor_image.unsqueeze(0))\n",
    "        if(model.task == \"classification\"):\n",
    "            preds = torch.softmax(y_hat, dim=-1).tolist()\n",
    "            labels = {class_names[k]: float(v) for k, v in enumerate(preds[0][:-1])}\n",
    "        elif(model.task == \"segmentation\"):\n",
    "            num_classes = y_hat.shape[1]\n",
    "            masks = y_hat[0]\n",
    "            classes_masks = masks.argmax(0) == torch.arange(num_classes)[:, None, None]\n",
    "            tensor_image = inv_normalize(tensor_image)\n",
    "            detection = draw_segmentation_masks((tensor_image * 255.).to(torch.uint8), \n",
    "                                              masks=classes_masks, alpha=.6)\n",
    "            detection = detection.numpy().transpose(1, 2, 0) / 255.\n",
    "        elif(model.task == \"detection\"):\n",
    "            if(\"maskrcnn\" in model_choice):\n",
    "                boolean_masks = [out['masks'][out['scores'] > .75] > 0.5\n",
    "                                for out in y_hat][0]\n",
    "                detection = draw_segmentation_masks((tensor_image * 255.).to(torch.uint8),\n",
    "                                                    boolean_masks.squeeze(1), alpha=0.8)\n",
    "                detection = detection.numpy().transpose(1, 2, 0) / 255.\n",
    "            else:\n",
    "                detection = draw_bounding_boxes((tensor_image * 255.).to(torch.uint8), \n",
    "                                                    boxes=y_hat[0][\"boxes\"][:5],\n",
    "                                                    colors=\"red\",\n",
    "                                                    width=5)\n",
    "                detection = detection.numpy().transpose(1, 2, 0) / 255.\n",
    "\n",
    "    return labels, detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "title = \"Application Demo \"\n",
    "description = \"# A Demo of Wrapping Pretrained Networks\"\n",
    "example_list = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    demo.title = title\n",
    "    gr.Markdown(description)\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            model = gr.Dropdown(model_list, label=\"Select Model\", interactive=True)\n",
    "            im = gr.Image(type=\"pil\", label=\"input image\")\n",
    "            label_conv = gr.Label(label=\"Predictions\", num_top_classes=4)\n",
    "        with gr.Column():\n",
    "            im_detection = gr.Image(type=\"pil\", label=\"Detection\")\n",
    "            btn = gr.Button(value=\"predict\")\n",
    "    btn.click(predict, inputs=[im, model], outputs=[label_conv, im_detection])\n",
    "    gr.Examples(examples=example_list, inputs=[im, model], outputs=[label_conv, im_detection])\n",
    "      \n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capsule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
