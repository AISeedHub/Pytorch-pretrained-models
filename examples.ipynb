{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/neptune/internal/backends/hosted_client.py:48: NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs.neptune.ai/setup/upgrading/\n",
      "  from neptune.version import version as neptune_client_version\n",
      "/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/pytorch_lightning/loggers/neptune.py:39: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
      "  from neptune import new as neptune\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, draw_bounding_boxes\n",
    "\n",
    "from Capsule.Classifier import CapsuleWrappingClassifier\n",
    "from Capsule.Segment import CapsuleWrappingSegment\n",
    "from Capsule.Detector import CapsuleWrappingDetector\n",
    "from Capsule.ultis import *\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer, LightningDataModule\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
    "from neptune.types import File\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torchmetrics\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 666\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_scheduler_config(optimizer, settings):\n",
    "    '''\n",
    "    set up learning rate scheduler\n",
    "    Args:\n",
    "        optimizer: optimizer\n",
    "        settings: settings hyperparameters\n",
    "    Returns:\n",
    "        lr_scheduler_config: [learning rate scheduler, configuration]\n",
    "    '''\n",
    "    if settings['lr_scheduler'] == 'step':\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer, step_size=settings['lr_step'], gamma=settings['lr_decay'])\n",
    "    elif settings['lr_scheduler'] == 'multistep':\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer, milestones=settings['lr_step'], gamma=settings['lr_decay'])\n",
    "    elif settings['lr_scheduler'] == 'reduce_on_plateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.1, patience=10, threshold=0.0001)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return {\n",
    "            'scheduler': scheduler,\n",
    "            'monitor': 'metrics/batch/train_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1,\n",
    "        }\n",
    "\n",
    "def get_optimizer(parameters, settings):\n",
    "    '''\n",
    "    set up learning optimizer\n",
    "    Args:\n",
    "        parameters: model's parameters\n",
    "        settings: settings hyperparameters\n",
    "    Returns:\n",
    "        optimizer: optimizer\n",
    "    '''\n",
    "    if settings['optimizer'] == 'adam':\n",
    "        optimizer = torch.optim.Adam(parameters, lr=settings['lr'], weight_decay=settings['weight_decay'])\n",
    "    elif settings['optimizer'] == 'sgd':\n",
    "        optimizer = torch.optim.SGD(\n",
    "            parameters, lr=settings['lr'], weight_decay=settings['weight_decay'], momentum=settings['momentum'])\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "def get_loss_function(type, n_classes=2):\n",
    "    '''\n",
    "    set up loss function\n",
    "    Args:\n",
    "        settings: settings hyperparameters, \n",
    "        n_classes: number of classes\n",
    "    Returns:\n",
    "        loss: loss function\n",
    "    '''\n",
    "    if type == \"ce\": loss = nn.CrossEntropyLoss()\n",
    "    elif type == \"nll\": loss = nn.NLLLoss()\n",
    "    elif type == \"bce\": loss = nn.BCELoss()    \n",
    "    elif type == \"spread\": loss = SpreadLoss(num_classes=n_classes)\n",
    "    elif type == \"margin\": loss = MarginLoss(num_classes=n_classes)\n",
    "    elif type == \"mse\": loss = nn.MSELoss()\n",
    "    elif type == \"none\": loss = None # only for task == detection\n",
    "    else: raise NotImplementedError()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_gpu_settings(gpu_ids, n_gpu):\n",
    "    '''\n",
    "    Get gpu settings for pytorch-lightning trainer:\n",
    "    Args:\n",
    "        gpu_ids (list[int])\n",
    "        n_gpu (int)\n",
    "    Returns:\n",
    "        tuple[str, int, str]: accelerator, devices, strategy\n",
    "    '''\n",
    "    if not torch.cuda.is_available():\n",
    "        return \"cpu\", None, None\n",
    "\n",
    "    if gpu_ids is not None:\n",
    "        devices = gpu_ids\n",
    "        strategy = \"ddp\" if len(gpu_ids) > 1 else 'auto'\n",
    "    elif n_gpu is not None:\n",
    "        devices = n_gpu\n",
    "        strategy = \"ddp\" if n_gpu > 1 else 'auto'\n",
    "    else:\n",
    "        devices = 1\n",
    "        strategy = 'auto'\n",
    "\n",
    "    return \"gpu\", devices, strategy\n",
    "\n",
    "def get_basic_callbacks():\n",
    "    '''\n",
    "    Get basic callbacks for pytorch-lightning trainer:\n",
    "    Args: \n",
    "        None\n",
    "    Returns:\n",
    "        last ckpt, best ckpt, lr callback, early stopping callback\n",
    "    '''\n",
    "    lr_callback = LearningRateMonitor(logging_interval='epoch')\n",
    "    last_ckpt_callback = ModelCheckpoint(\n",
    "        filename='last_model_{epoch:03d}-{val/loss:.4f}-{val/acc:02.0f}',\n",
    "        auto_insert_metric_name=False,\n",
    "        save_top_k=1,\n",
    "        monitor=None,\n",
    "    )\n",
    "    best_ckpt_calllback = ModelCheckpoint(\n",
    "        filename='best_model_{epoch:03d}-{val/loss:.4f}-{val/acc:02.0f}',\n",
    "        auto_insert_metric_name=False,\n",
    "        save_top_k=1,\n",
    "        monitor='metrics/batch/train_loss',\n",
    "        mode='min',\n",
    "        verbose=True\n",
    "    )\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='metrics/batch/train_loss',  # Metric to monitor for improvement\n",
    "        mode='min',  # Choose 'min' or 'max' depending on the metric (e.g., 'min' for loss, 'max' for accuracy)\n",
    "        patience=10,  # Number of epochs with no improvement before stopping\n",
    "    )\n",
    "    return [last_ckpt_callback, best_ckpt_calllback, lr_callback, early_stopping_callback]\n",
    "\n",
    "def get_trainer(settings, task) -> Trainer:\n",
    "    '''\n",
    "    Get trainer and logging for pytorch-lightning trainer:\n",
    "    Args: \n",
    "        settings: hyperparameter settings\n",
    "        task: task to run training\n",
    "    Returns:\n",
    "        trainer: trainer object\n",
    "        logger: neptune logger object\n",
    "    '''\n",
    "    callbacks = get_basic_callbacks()\n",
    "    accelerator, devices, strategy = get_gpu_settings(settings['gpu_ids'], settings['n_gpu'])\n",
    "\n",
    "    neptune_logger = NeptuneLogger(\n",
    "        project=\"kaori/Capsule-wrap\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyZjZiMDA2YS02MDM3LTQxZjQtOTE4YS1jODZkMTJjNGJlMDYifQ==\",\n",
    "        log_model_checkpoints=False,\n",
    "        tags=[task]\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        logger=[neptune_logger],\n",
    "        max_epochs=settings['n_epoch'],\n",
    "        default_root_dir=settings['ckpt_path'],\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        strategy=strategy,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    return trainer, neptune_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(LightningDataModule):\n",
    "    '''\n",
    "    Data Module for Train/Val/Test data loadding\n",
    "    Args: \n",
    "        data_settings, training_settings: hyperparameter settings\n",
    "    Returns:\n",
    "        Train/Test/Val data loader\n",
    "    '''\n",
    "    def __init__(self, data_settings, training_settings):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dataset = data_settings['name']\n",
    "        self.root_dir = data_settings['path']\n",
    "        self.img_size = data_settings['img_size']\n",
    "        self.batch_size = training_settings['n_batch']\n",
    "        self.num_workers = training_settings['num_workers']\n",
    "        self.class_list = None\n",
    "        self.transform = None\n",
    "        self.collate_fn = None\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "\n",
    "        if stage == \"fit\":\n",
    "            if self.dataset == 'CIFAR10':\n",
    "                self.Train_dataset = CIFAR10read(mode=\"train\", data_path=self.root_dir, \n",
    "                                                transform=self.transform, imgsize=self.img_size)\n",
    "                self.Val_dataset =  CIFAR10read(mode=\"val\", data_path=self.root_dir, \n",
    "                                                transform=self.transform, imgsize=self.img_size)\n",
    "            elif self.dataset == 'LungCT-Scan':\n",
    "                dataset = LungCTscan(data_dir=self.root_dir, transform=self.transform, imgsize=self.img_size)\n",
    "                self.Train_dataset = Subset(dataset, range(int(len(dataset) * 0.8)))\n",
    "                self.Val_dataset = Subset(dataset, range(int(len(dataset) * 0.8), len(dataset)))\n",
    "                # self.Val_dataset = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "            elif self.dataset == 'PennFudan':\n",
    "                self.collate_fn = collate_fn\n",
    "                dataset = PennFudanDataset(root=self.root_dir, transform=self.transform, imgsize=self.img_size)\n",
    "                self.Train_dataset = Subset(dataset, range(int(len(dataset) * 0.8)))\n",
    "                self.Val_dataset = Subset(dataset, range(int(len(dataset) * 0.8), len(dataset)))\n",
    "                # self.Train_dataset, self.Val_dataset = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "                \n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            if self.dataset == 'CIFAR10':\n",
    "                self.Test_dataset =  CIFAR10read(mode=\"test\", data_path=self.root_dir, \n",
    "                                                transform=self.transform, imgsize=self.img_size)\n",
    "            elif self.dataset == 'LungCT-Scan':\n",
    "                dataset = LungCTscan(data_dir=self.root_dir, transform=self.transform, imgsize=self.img_size)\n",
    "                self.Test_dataset = Subset(dataset, range(len(dataset)))\n",
    "            elif self.dataset == 'PennFudan':\n",
    "                self.collate_fn = collate_fn\n",
    "                dataset = PennFudanDataset(root=self.root_dir, transform=self.transform, imgsize=self.img_size)\n",
    "                self.Test_dataset = Subset(dataset, range(len(dataset)))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.Train_dataset, batch_size=self.batch_size, shuffle=True, \n",
    "                          num_workers=self.num_workers, collate_fn=self.collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.Val_dataset, batch_size=self.batch_size, shuffle=False, \n",
    "                          num_workers=self.num_workers, collate_fn=self.collate_fn)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.Test_dataset, batch_size=self.batch_size, shuffle=False, \n",
    "                          num_workers=self.num_workers, collate_fn=self.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleModel(LightningModule):\n",
    "    def __init__(self, PARAMS, task='classification'):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.architect_settings = PARAMS['architect_settings']\n",
    "        self.train_settings = PARAMS['training_settings']\n",
    "        self.dataset_settings = PARAMS['dataset_settings']\n",
    "        self.task = task\n",
    "        # Model selection\n",
    "        if(self.task == 'classification'):\n",
    "            self.model = CapsuleWrappingClassifier(model_configs=self.architect_settings)\n",
    "            self.train_metrics = torchmetrics.Accuracy(task='multiclass', num_classes=self.architect_settings['n_cls'])\n",
    "            self.valid_metrics = torchmetrics.Accuracy(task='multiclass', num_classes=self.architect_settings['n_cls'])\n",
    "        elif(self.task == 'segmentation'):\n",
    "            self.model = CapsuleWrappingSegment(model_configs=self.architect_settings)\n",
    "            self.train_metrics = torchmetrics.Dice(num_classes=self.architect_settings['n_cls'])\n",
    "            self.valid_metrics = torchmetrics.Dice(num_classes=self.architect_settings['n_cls'])\n",
    "        elif(self.task == 'detection'):\n",
    "            self.model = CapsuleWrappingDetector(model_configs=self.architect_settings)\n",
    "            self.train_metrics = MeanAveragePrecision()\n",
    "            self.valid_metrics = MeanAveragePrecision()\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        # Loss selection\n",
    "        self.loss = get_loss_function(self.train_settings['loss'], self.architect_settings['n_cls'])\n",
    "      \n",
    "        self.validation_step_outputs = []\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        return self.model(x, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        if(self.task == 'detection'):\n",
    "            loss_dict = self(x, y)\n",
    "            loss = sum(loss for loss in loss_dict.values())\n",
    "        else:\n",
    "            y_hat = self(x)\n",
    "            loss = self.loss(y_hat, y)\n",
    "            y_pred = torch.softmax(y_hat, dim=1)\n",
    "            self.train_metrics.update(y_pred.cpu(), y.cpu())\n",
    "\n",
    "        self.log(\"metrics/batch/train_loss\", loss, prog_bar=False)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "       \n",
    "        if(self.task == 'classification'):\n",
    "            self.log(\"metrics/epoch/train_acc\", self.train_metrics.compute())\n",
    "        elif(self.task == 'segmentation'):\n",
    "            self.log(\"metrics/epoch/train_dice\", self.train_metrics.compute())\n",
    "    \n",
    "        self.train_metrics.reset()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        \n",
    "        if(self.task == 'detection'):\n",
    "            y_hat = self(x)\n",
    "            y_pred = [{k: v for k, v in t.items()} for t in y_hat]\n",
    "            targets = [{k: v for k, v in t.items()} for t in y]\n",
    "\n",
    "            self.valid_metrics.update(y_pred, targets)\n",
    "            self.validation_step_outputs.append({\"image\": x[0], \"predictions\": y_pred[0], \"targets\": targets[0]})\n",
    "        else:\n",
    "            y_hat = self(x)\n",
    "            loss = self.loss(y_hat, y)\n",
    "            y_pred = torch.softmax(y_hat, dim=-1)\n",
    "            self.valid_metrics.update(y_pred.cpu(), y.cpu())\n",
    "        \n",
    "            if(self.task == 'segmentation'):\n",
    "                y_pred = torch.argmax(y_hat, dim=1)\n",
    "                self.validation_step_outputs.append({\"loss\": loss.item(), \"predictions\": y_pred.unsqueeze(1)})\n",
    "            else:\n",
    "                self.validation_step_outputs.append({\"loss\": loss.item()})\n",
    "\n",
    "            self.log('metrics/batch/val_loss', loss)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \n",
    "        if(self.task == 'classification'):\n",
    "            self.log('metrics/epoch/val_acc', self.valid_metrics.compute())\n",
    "            loss =[outputs['loss'] for outputs in self.validation_step_outputs]\n",
    "            self.log('metrics/epoch/val_loss', sum(loss) / len(loss))\n",
    "           \n",
    "        elif(self.task == 'segmentation'):\n",
    "            self.log(\"metrics/epoch/val_dice\", self.valid_metrics.compute())\n",
    "            loss =[outputs['loss'] for outputs in self.validation_step_outputs]\n",
    "            self.log('metrics/epoch/val_loss', sum(loss) / len(loss))\n",
    "\n",
    "            outputs = self.validation_step_outputs\n",
    "            reconstructions = make_grid(outputs[0][\"predictions\"], nrow=int(self.train_settings[\"n_batch\"] ** 0.5))\n",
    "            reconstructions = reconstructions.cpu().numpy().transpose(1, 2, 0)\n",
    "            self.logger.experiment[\"val/reconstructions\"].append(File.as_image(reconstructions))\n",
    "            self.validation_step_outputs.clear()\n",
    "        \n",
    "        elif(self.task == 'detection'):\n",
    "            self.log('metrics/epoch/val_mAP', self.valid_metrics.compute()['map'])\n",
    "            #no validation loss\n",
    "\n",
    "            outputs = self.validation_step_outputs[-1]\n",
    "            image, predictions, targets = outputs[\"image\"], outputs[\"predictions\"], outputs[\"targets\"]\n",
    "            reconstructions = draw_bounding_boxes((image * 255.).to(torch.uint8), \n",
    "                                                boxes=predictions[\"boxes\"][:5],\n",
    "                                                colors=\"red\",\n",
    "                                                width=5, font_size=20)\n",
    "            reconstructions = draw_bounding_boxes(reconstructions, \n",
    "                                                boxes=targets[\"boxes\"][:5],\n",
    "                                                colors=\"blue\",\n",
    "                                                width=5, font_size=20)\n",
    "            reconstructions = reconstructions.cpu().numpy().transpose(1, 2, 0) / 255.\n",
    "            self.logger.experiment[\"val/reconstructions\"].append(File.as_image(reconstructions))\n",
    "            self.validation_step_outputs.clear()\n",
    "\n",
    "        self.valid_metrics.reset()\n",
    "       \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = get_optimizer(self.model.parameters(), self.train_settings)\n",
    "        lr_scheduler_config = get_lr_scheduler_config(optimizer, self.train_settings)\n",
    "\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_config}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "with open(\"Capsule/config.yaml\", 'r') as stream:\n",
    "    PARAMS = yaml.safe_load(stream)\n",
    "    PARAMS = PARAMS['classifier']\n",
    "    print(PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "data = DataModule(PARAMS['dataset_settings'], PARAMS['training_settings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "model = CapsuleModel(PARAMS=PARAMS, task = 'classification')\n",
    "trainer, logger = get_trainer(PARAMS['training_settings'], task = 'classification')\n",
    "logger.log_hyperparams(params=PARAMS)\n",
    "\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = CapsuleModel.load_from_checkpoint(\"models/deeplab.ckpt\")\n",
    "# test_model.eval()\n",
    "# print(test_model.task)\n",
    "# x = torch.randn(1, 3, 224, 224)\n",
    "# transform = test_model.model.preprocess\n",
    "# x_preprocessed = transform(x)\n",
    "# with torch.no_grad():\n",
    "#     y_hat = test_model(x)\n",
    "#     print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/class_name.txt\", \"r\", encoding='utf-8') as f:\n",
    "    class_names = f.read().splitlines()\n",
    "\n",
    "def predict(image, model_choice):\n",
    "    labels, segment, detection = None, None, None\n",
    "    model = CapsuleModel.load_from_checkpoint(f\"models/{model_choice}.ckpt\")\n",
    "    model.eval()\n",
    "    transforms = model.model.preprocess\n",
    "    tensor_image = transforms(image)\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(tensor_image.unsqueeze(0))\n",
    "        if(model.task == \"classification\"):\n",
    "            preds = torch.softmax(y_hat, dim=-1).tolist()\n",
    "            labels = {class_names[k]: float(v) for k, v in enumerate(preds[0][:-1])}\n",
    "        elif(model.task == \"segmentation\"):\n",
    "            y_pred = torch.argmax(y_hat, dim=1)\n",
    "            segment = y_pred.squeeze(0).numpy()\n",
    "        elif(model.task == \"detection\"):\n",
    "            detection = draw_bounding_boxes((tensor_image * 255.).to(torch.uint8), \n",
    "                                                boxes=y_hat[0][\"boxes\"][:5],\n",
    "                                                colors=\"red\",\n",
    "                                                width=5)\n",
    "            detection = detection.numpy().transpose(1, 2, 0) / 255.\n",
    "\n",
    "    return labels, segment, detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "title = \"Capsule Network Application Demo \"\n",
    "description = \"# A Demo of Capsule Network Application\"\n",
    "example_list = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    demo.title = title\n",
    "    gr.Markdown(description)\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            model = gr.Dropdown(['swin', 'faster-rcnn', 'deeplab'], label=\"Select Model\", interactive=True)\n",
    "            im = gr.Image(type=\"pil\", label=\"input image\")\n",
    "        with gr.Column():\n",
    "            label_conv = gr.Label(label=\"Predictions\", num_top_classes=4)\n",
    "            im_segment = gr.Image(type=\"pil\", label=\"Segment\")\n",
    "            im_detection = gr.Image(type=\"pil\", label=\"Detection\")\n",
    "            btn = gr.Button(value=\"predict\")\n",
    "    btn.click(predict, inputs=[im, model], outputs=[label_conv, im_segment, im_detection])\n",
    "    gr.Examples(examples=example_list, inputs=[im, model], outputs=[label_conv, im_segment, im_detection])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://41e307cbef21d65ac3.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://41e307cbef21d65ac3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/gradio/routes.py\", line 394, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/gradio/blocks.py\", line 1075, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/gradio/blocks.py\", line 884, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/tmp/ipykernel_4735/208641873.py\", line 6, in predict\n",
      "    model = CapsuleModel.load_from_checkpoint(f\"models/{model_choice}.ckpt\")\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1532, in load_from_checkpoint\n",
      "    loaded = _load_from_checkpoint(\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/pytorch_lightning/core/saving.py\", line 62, in _load_from_checkpoint\n",
      "    checkpoint = pl_load(checkpoint_path, map_location=map_location)\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/lightning_fabric/utilities/cloud_io.py\", line 50, in _load\n",
      "    with fs.open(path_or_url, \"rb\") as f:\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/fsspec/spec.py\", line 1151, in open\n",
      "    f = self._open(\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/fsspec/implementations/local.py\", line 183, in _open\n",
      "    return LocalFileOpener(path, mode, fs=self, **kwargs)\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/fsspec/implementations/local.py\", line 285, in __init__\n",
      "    self._open()\n",
      "  File \"/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/fsspec/implementations/local.py\", line 290, in _open\n",
      "    self.f = open(self.path, mode=self.mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/vips/share/Vu/Capsule-Wrapping/models/.ckpt'\n",
      "/home/vips/anaconda3/envs/Capsule/lib/python3.9/site-packages/torchvision/utils.py:215: UserWarning: boxes doesn't contain any box. No box was drawn\n",
      "  warnings.warn(\"boxes doesn't contain any box. No box was drawn\")\n"
     ]
    }
   ],
   "source": [
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capsule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
